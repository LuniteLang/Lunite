import "token.lun" as tok
import "lexer.lun" as lex
import "ast.lun" as ast
import "list.lun" as list

pub enum Precedence {
    Lowest,
    Assign,
    Plus,
    Minus,
    Star,
    Slash
}

pub fn precedence_of(kind: tok.TokenKind) -> Precedence {
    return Precedence::Lowest;
}

pub struct Parser {
    pub lexer: lex.Lexer,
    pub cur_token: tok.Token,
    pub peek_token: tok.Token
}

impl Parser {
    pub fn new(mut l: lex.Lexer) -> Parser {
        let cur = l.next_token();
        let peek = l.next_token();
        return Parser {
            lexer: l,
            cur_token: cur,
            peek_token: peek
        };
    }

    pub fn next_token(self: Parser) {
        self.cur_token = self.peek_token;
        self.peek_token = self.lexer.next_token();
    }

    pub fn cur_is(self: Parser, kind: tok.TokenKind) -> bool {
        return self.cur_token.kind == kind;
    }

    pub fn peek_is(self: Parser, kind: tok.TokenKind) -> bool {
        return self.peek_token.kind == kind;
    }

    pub fn skip_newlines(self: Parser) {
        while ((self.cur_token.kind == tok.TokenKind::Newline) | (self.cur_token.kind == tok.TokenKind::Semicolon)) {
            self.next_token();
        }
    }

    pub fn parse_program(self: Parser) -> ast.Program {
        let items = list.List<ast.Item>.new();
        while (self.cur_token.kind != tok.TokenKind::Eof) {
            self.skip_newlines();
            if (self.cur_token.kind == tok.TokenKind::Eof) { break; }
            let item = self.parse_item();
            items.push(item);
            self.skip_newlines();
        }
        return ast.Program { items: items };
    }

    pub fn parse_item(self: Parser) -> ast.Item {
        self.next_token();
        return ast.Item::Import(ast.ImportDecl { path: "dummy", alias: ast.Option<string>::None });
    }
}